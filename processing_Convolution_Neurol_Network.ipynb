{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce0d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "config_cnn.py\n",
    "---------------\n",
    "Fichier de configuration pour notre CNN :\n",
    "- chemins\n",
    "- hyperparamètres d'entraînement\n",
    "\"\"\"\n",
    "\n",
    "# Hyperparamètres d'entraînement\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 1e-3\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "# Paramètres du modèle\n",
    "INPUT_SHAPE = (32, 32, 3)   # CIFAR-10 : images 32x32 RGB\n",
    "NUM_CLASSES = 10            # 10 classes\n",
    "\n",
    "# Callbacks\n",
    "EARLY_STOPPING_PATIENCE = 5   # nombre d'époques sans amélioration avant arrêt\n",
    "LR_REDUCE_PATIENCE = 3        # nombre d'époques sans amélioration avant réduction du LR\n",
    "\n",
    "# Chemin pour sauvegarder le meilleur modèle\n",
    "BEST_MODEL_PATH = \"data/best_cnn_cifar10.h5\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "model_cnn.py\n",
    "-------------\n",
    "Définit la fonction build_cnn_model() qui crée un modèle CNN Keras.\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from config_cnn import INPUT_SHAPE, NUM_CLASSES, LEARNING_RATE\n",
    "\n",
    "def build_cnn_model():\n",
    "    \"\"\"\n",
    "    Crée et compile un modèle CNN pour la classification d'images.\n",
    "    Retourne : un modèle Keras compilé.\n",
    "    \"\"\"\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Bloc 1 de convolution\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\",\n",
    "                            input_shape=INPUT_SHAPE))\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.25))  # régularisation pour limiter l'overfitting\n",
    "\n",
    "    # Bloc 2 de convolution\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    # Bloc 3 de convolution\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    # Passage en fully-connected\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(layers.Dropout(0.5))   # Dropout plus fort sur la partie dense\n",
    "\n",
    "    # Couche de sortie\n",
    "    model.add(layers.Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "\n",
    "    # Compilation du modèle\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",  # labels comme entiers 0..9\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "train_cnn.py\n",
    "-------------\n",
    "Script principal pour :\n",
    "- Charger CIFAR-10\n",
    "- Prétraiter les données\n",
    "- Appliquer une augmentation de données (data augmentation)\n",
    "- Entraîner le CNN avec callbacks (early stopping, reduction du LR, sauvegarde du meilleur modèle)\n",
    "- Évaluer le modèle\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from config_cnn import (\n",
    "    BATCH_SIZE,\n",
    "    EPOCHS,\n",
    "    VALIDATION_SPLIT,\n",
    "    EARLY_STOPPING_PATIENCE,\n",
    "    LR_REDUCE_PATIENCE,\n",
    "    BEST_MODEL_PATH\n",
    ")\n",
    "from model_cnn import build_cnn_model\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Charge le dataset CIFAR-10 depuis Keras.\n",
    "    Renvoie : (x_train, y_train), (x_test, y_test)\n",
    "    \"\"\"\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "    # Normalisation des pixels dans [0, 1]\n",
    "    x_train = x_train.astype(\"float32\") / 255.0\n",
    "    x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "    # y_train et y_test sont des entiers (0..9), ce qui est compatible avec sparse_categorical_crossentropy\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "def get_data_generator():\n",
    "    \"\"\"\n",
    "    Crée un générateur d'images avec augmentation de données.\n",
    "    Cette augmentation aide à limiter l'overfitting.\n",
    "    \"\"\"\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=15,       # rotations aléatoires\n",
    "        width_shift_range=0.1,   # décalage horizontal\n",
    "        height_shift_range=0.1,  # décalage vertical\n",
    "        horizontal_flip=True,    # flip horizontal\n",
    "        zoom_range=0.1           # zoom léger\n",
    "    )\n",
    "    return datagen\n",
    "\n",
    "def get_callbacks():\n",
    "    \"\"\"\n",
    "    Crée les callbacks pour :\n",
    "    - EarlyStopping : arrêter quand la val_loss ne s'améliore plus\n",
    "    - ReduceLROnPlateau : diminuer le LR si la val_loss stagne\n",
    "    - ModelCheckpoint : sauvegarder le meilleur modèle (val_loss minimale)\n",
    "    \"\"\"\n",
    "    early_stopping = callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=EARLY_STOPPING_PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\",\n",
    "        factor=0.5,       # diviser le LR par 2\n",
    "        patience=LR_REDUCE_PATIENCE,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    checkpoint = callbacks.ModelCheckpoint(\n",
    "        BEST_MODEL_PATH,\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return [early_stopping, reduce_lr, checkpoint]\n",
    "\n",
    "def main():\n",
    "    # 1. Charger les données\n",
    "    (x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "    # 2. Créer le modèle CNN\n",
    "    model = build_cnn_model()\n",
    "    model.summary()  # affiche la structure du modèle\n",
    "\n",
    "    # 3. Préparer le générateur de données avec augmentation\n",
    "    datagen = get_data_generator()\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # 4. Préparer les callbacks (early stopping, etc.)\n",
    "    cb_list = get_callbacks()\n",
    "\n",
    "    # 5. Entraîner le modèle\n",
    "    #    On utilise flow(x, y) pour générer les batchs augmentés à la volée.\n",
    "    history = model.fit(\n",
    "        datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
    "        epochs=EPOCHS,\n",
    "        validation_split=VALIDATION_SPLIT,  # ne fonctionne pas directement avec flow\n",
    "        # Astuce : on peut split avant ou utiliser validation_data séparément.\n",
    "        # Ici on fait un split manuel pour la validation.\n",
    "        steps_per_epoch=int((1 - VALIDATION_SPLIT) * len(x_train) // BATCH_SIZE),\n",
    "        callbacks=cb_list,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # 6. Évaluer sur le jeu de test\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f\"Performance sur le test : loss = {test_loss:.4f}, accuracy = {test_acc:.4f}\")\n",
    "\n",
    "    # 7. Sauvegarder le modèle final (optionnel, en plus du best_model)\n",
    "    model.save(\"cnn_cifar10_final.h5\")\n",
    "    print(\"Modèle final sauvegardé sous 'cnn_cifar10_final.h5'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391a4bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "metrics_cnn.py\n",
    "--------------\n",
    "Calcule des métriques de classification pour un CNN Keras (CIFAR-10) :\n",
    "Accuracy, Precision, Recall, F1-score, AUC-ROC (multi-classe) + matrice de confusion.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Noms CIFAR-10 (ordre standard)\n",
    "CIFAR10_CLASS_NAMES = [\n",
    "    \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
    "    \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
    "]\n",
    "\n",
    "def load_cifar10():\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    x_test = x_test.astype(\"float32\") / 255.0\n",
    "    y_test = y_test.reshape(-1)  # (N,1) -> (N,)\n",
    "    return x_test, y_test\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation=\"nearest\")\n",
    "    plt.title(\"Matrice de confusion\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45, ha=\"right\")\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    plt.xlabel(\"Prédictions\")\n",
    "    plt.ylabel(\"Vérité terrain\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    # 1) Charger le modèle entraîné (best ou final)\n",
    "    # Ex : BEST_MODEL_PATH = \"data/best_cnn_cifar10.h5\"\n",
    "    model_path = \"data/best_cnn_cifar10.h5\"\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # 2) Charger les données de test\n",
    "    x_test, y_test = load_cifar10()\n",
    "\n",
    "    # 3) Prédictions\n",
    "    y_proba = model.predict(x_test, batch_size=128, verbose=0)  # shape (N,10)\n",
    "    y_pred = np.argmax(y_proba, axis=1)\n",
    "\n",
    "    # 4) Métriques\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Pour multi-classe : macro (toutes classes pareil) ou weighted (pondéré par support)\n",
    "    prec_macro = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    rec_macro  = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    f1_macro   = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "    prec_w = precision_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    rec_w  = recall_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    f1_w   = f1_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    # AUC-ROC multi-classe (One-vs-Rest)\n",
    "    y_test_oh = tf.keras.utils.to_categorical(y_test, num_classes=y_proba.shape[1])\n",
    "    auc_ovr_macro = roc_auc_score(y_test_oh, y_proba, multi_class=\"ovr\", average=\"macro\")\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(\"=== Métriques CNN (CIFAR-10) ===\")\n",
    "    print(f\"Accuracy : {acc:.4f}\\n\")\n",
    "\n",
    "    print(\"---- Macro ----\")\n",
    "    print(f\"Precision : {prec_macro:.4f}\")\n",
    "    print(f\"Recall    : {rec_macro:.4f}\")\n",
    "    print(f\"F1-score  : {f1_macro:.4f}\\n\")\n",
    "\n",
    "    print(\"---- Weighted ----\")\n",
    "    print(f\"Precision : {prec_w:.4f}\")\n",
    "    print(f\"Recall    : {rec_w:.4f}\")\n",
    "    print(f\"F1-score  : {f1_w:.4f}\\n\")\n",
    "\n",
    "    print(f\"AUC-ROC (OVR macro) : {auc_ovr_macro:.4f}\\n\")\n",
    "\n",
    "    print(\"=== Rapport détaillé par classe ===\")\n",
    "    print(classification_report(y_test, y_pred, target_names=CIFAR10_CLASS_NAMES, zero_division=0))\n",
    "\n",
    "    # 5) Matrice de confusion (affichage simple matplotlib)\n",
    "    plot_confusion_matrix(cm, CIFAR10_CLASS_NAMES)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
